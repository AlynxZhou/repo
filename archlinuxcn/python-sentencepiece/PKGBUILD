# Maintainer: Hu Butui <hot123tea123@gmail.com>

_name=sentencepiece
pkgname=python-sentencepiece
pkgver=0.2.1
pkgrel=1
pkgdesc="Unsupervised text tokenizer for Neural Network-based text generation"
arch=('x86_64')
url="https://github.com/google/sentencepiece"
license=('Apache-2.0')
depends=(
  gcc-libs
  glibc
  sentencepiece
  python
)
makedepends=(
  python-build
  python-installer
  python-setuptools
  python-wheel 
)
source=("${_name}-${pkgver}.tar.gz::https://github.com/google/sentencepiece/archive/refs/tags/v${pkgver}.tar.gz")
sha512sums=('012850b63b2323e16acc5dacc0a494ad3f6375425ee86274f0946032e47c088a3b307758b99d752fcf54acf76c82d7d13d0c14bbf07aa9b612c4f1fbd30cf1cf')

prepare() {
  sed -i 's/libsentencepiece.a/libsentencepiece.so/g' "${srcdir}/${_name}-${pkgver}/python/setup.py"
  sed -i 's/libsentencepiece_train.a/libsentencepiece_train.so/g' "${srcdir}/${_name}-${pkgver}/python/setup.py"
}


build() {
  cd "${_name}-${pkgver}/python"
  python -m build --wheel --no-isolation
}

package() {
  cd "${_name}-${pkgver}/python"
  python -m installer --destdir="${pkgdir}" dist/*.whl
}
# vim:set ts=2 sw=2 et:
